{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will train logistic/softmax regression model using TensorFlow, to predict if the input is neutral face or smiling face.\n",
    "About the dataset, I collected images from Google Images and cropped the mouth part is manually put them into two separate folders. \n",
    "This is developed in Python 2.7.10 and Tensorflow 1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 1.2.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob,os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "print \"tensorflow version\",tf.__version__\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data and resize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading images from the data folder\n",
    "# label, smile = 1, neutral = 0\n",
    "(img_width, img_height) = (45, 25)\n",
    "def load_images_from_folder(folder):\n",
    "    (images, lables, names, id) = ([], [], {}, 0)\n",
    "    for (subdirs, dirs, files) in os.walk(folder):\n",
    "        print subdirs, dirs\n",
    "        for subdir in dirs:\n",
    "            names[id] = subdir\n",
    "            subjectpath = os.path.join(folder, subdir)\n",
    "            for filename in os.listdir(subjectpath):\n",
    "                path = subjectpath + '/' + filename\n",
    "                lable = id\n",
    "                img = cv2.imread(path, 0) # Reading each images in grayscale\n",
    "                img = cv2.resize(img,(img_width, img_height)) # Resizing all the images\n",
    "                images.append(img)\n",
    "                lables.append(int(lable))\n",
    "            id += 1\n",
    "        \n",
    "        return images, lables, names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/ ['neutral', 'smile']\n"
     ]
    }
   ],
   "source": [
    "X,Y,classes = load_images_from_folder(\"./data/\")\n",
    "\n",
    "(X,Y) = [np.array(lis) for lis in [X, Y]]\n",
    "Y = pd.get_dummies(Y) #converting labels to one-hot, Used Pandas for it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height of the image:  25\n",
      "Width of the image:   45\n",
      "Total number of data: 163\n"
     ]
    }
   ],
   "source": [
    "print \"Height of the image:  \" + str(X.shape[1])\n",
    "print \"Width of the image:   \"  + str(X.shape[2])\n",
    "print \"Total number of data: \"+ str(len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data using sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size of data, Train set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of train data: 109\n",
      "lenght of test data:  54\n"
     ]
    }
   ],
   "source": [
    "print \"lenght of train data: \"+str(len(X_train))\n",
    "print \"lenght of test data:  \"+str(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatting the data into 1 dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we implement Softmax regression, it need 1 dimension array as an Input, It's important to convert our 2-D array to 1-D array\n",
    "<img src=\"flattened_image.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_flatten: (109, 1125)\n",
      "test_set_x_flatten : (54, 1125)\n",
      "[[172 177 177 ...,  92 104 102]\n",
      " [155 158 161 ..., 162 159 155]\n",
      " [173 160 137 ..., 143 136 125]\n",
      " ..., \n",
      " [150 150 143 ..., 160 158 159]\n",
      " [134 142 148 ..., 154 147 153]\n",
      " [ 28  29  30 ...,  78  77  58]]\n"
     ]
    }
   ],
   "source": [
    "train_set_x_flatten = X_train.reshape(X_train.shape[0],-1)\n",
    "test_set_x_flatten = X_test.reshape(X_test.shape[0],-1)\n",
    "print \"train_set_x_flatten: \"+str(train_set_x_flatten.shape)\n",
    "print \"test_set_x_flatten : \"+str(test_set_x_flatten.shape)\n",
    "\n",
    "print train_set_x_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train set: 109\n",
      "length of test set: 54\n",
      "shape of train set: (109, 1125)\n",
      "shape of test set: (54, 1125)\n"
     ]
    }
   ],
   "source": [
    "#Normalizing data, conveting all pixel value in range between 0-1\n",
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255.\n",
    "print \"length of train set: \" + str(len(train_set_x))\n",
    "print \"length of test set: \" + str(len(test_set_x))\n",
    "print \"shape of train set: \"+ str(train_set_x.shape)\n",
    "print \"shape of test set: \"+ str(test_set_x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the softmax regression using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 1125])\n",
    "W = tf.Variable(tf.zeros([1125, 2]), dtype=tf.float32, name=\"w1\")\n",
    "b = tf.Variable(tf.zeros([2]),  dtype=tf.float32, name=\"bias\")\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b, name=\"first_operation\")\n",
    "y_ = tf.placeholder(tf.float32, [None, 2], name = \"final_output\")\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with learning rate: 0.2\n",
      "losses after per 1000 iteration:  0.693147\n",
      "losses after per 1000 iteration:  0.00812404\n",
      "losses after per 1000 iteration:  0.00456266\n",
      "losses after per 1000 iteration:  0.00328482\n",
      "losses after per 1000 iteration:  0.00259862\n",
      "losses after per 1000 iteration:  0.00216482\n",
      "losses after per 1000 iteration:  0.00186346\n",
      "losses after per 1000 iteration:  0.00164081\n",
      "losses after per 1000 iteration:  0.00146906\n",
      "losses after per 1000 iteration:  0.00133228\n",
      "losses after per 1000 iteration:  0.00122064\n",
      "losses after per 1000 iteration:  0.00112772\n",
      "losses after per 1000 iteration:  0.00104913\n",
      "losses after per 1000 iteration:  0.000981756\n",
      "losses after per 1000 iteration:  0.00092333\n",
      "Model saved in file: ./model/emotion_model\n",
      "('accuracy with learning rate: ', '0.2', 0.51851851)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.2\n",
    "print \"training with learning rate: \" + str(learning_rate)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(15000):\n",
    "        trainStep,loss = sess.run([train_step, cross_entropy], feed_dict={x: train_set_x, y_: y_train})\n",
    "        if step%1000==0:\n",
    "            print \"losses after per 1000 iteration: \",loss\n",
    "\n",
    "    save_path = saver.save(sess, \"./model/emotion_model\")\n",
    "\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"accuracy with learning rate: \" ,str(learning_rate), sess.run(accuracy, feed_dict={x:test_set_x , y_: y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/emotion_model\n",
      "('w1:', array([[ 0.2276748 , -0.22767468],\n",
      "       [ 0.14447214, -0.14447215],\n",
      "       [ 0.13912062, -0.13912085],\n",
      "       ..., \n",
      "       [-0.09384812,  0.09384794],\n",
      "       [ 0.00484194, -0.00484221],\n",
      "       [ 0.0309796 , -0.0309797 ]], dtype=float32))\n",
      "('bias:', array([ 0.04066655, -0.04066731], dtype=float32))\n",
      "(1, 1125)\n",
      "[[  9.99999762e-01   2.05811475e-07]]\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "# W = tf.Variable(tf.zeros([1125, 2]),dtype = tf.float32, name=\"w1\")\n",
    "# b = tf.Variable(tf.zeros([2]), dtype = tf.float32,name=\"bias\")\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./model/emotion_model\")\n",
    "    print(\"w1:\", sess.run(W))\n",
    "    print(\"bias:\", sess.run(b))\n",
    "    img = cv2.imread(\"/home/aquib/Desktop/smile_recognition/test/test_5n.jpg\", 0) # Reading each images in grayscale \n",
    "                                                                          # test_2 is a neutral face\n",
    "                                                                            # test_1 is smile face\n",
    "    img = cv2.resize(img,(img_width, img_height)) # Resizing all the images\n",
    "    image=[]\n",
    "    image.append(img)\n",
    "    image_test = np.array(image)\n",
    "    test_image_flatten = image_test.reshape(image_test.shape[0],-1)\n",
    "    test_image_normalized = test_image_flatten/255.\n",
    "    print test_image_normalized.shape\n",
    "    x_ = tf.cast(test_image_normalized, tf.float32)\n",
    "    y = tf.nn.softmax(tf.matmul(x_, W) + b)\n",
    "    print sess.run(y)\n",
    "    indx = sess.run(tf.argmax(y,1))\n",
    "    if indx==1:\n",
    "        print \"smile\"\n",
    "    elif indx==0:\n",
    "        print \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
